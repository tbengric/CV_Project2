{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8b3d3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (9.0.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\tidia\\appdata\\roaming\\python\\python313\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
      "   ---------------------------------------- 0.0/914.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 914.9/914.9 kB 35.2 MB/s  0:00:00\n",
      "Downloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 59.0 MB/s  0:00:00\n",
      "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   ---------------------------------------- 3/3 [ipywidgets]\n",
      "\n",
      "Successfully installed ipywidgets-8.1.8 jupyterlab_widgets-3.0.16 widgetsnbextension-4.0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'Une connexion existante a dû être fermée par l’hôte distant', None, 10054, None))': /simple/ipywidgets/\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "\n",
    "!pip install ipywidgets\n",
    "from pprint import pprint\n",
    "from ipywidgets import Video\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2601ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tracker(tracker_type):\n",
    "    tracker = None\n",
    "    tracker_types = [\n",
    "        \"BOOSTING\",\n",
    "        \"MIL\",\n",
    "        \"KCF\",\n",
    "        \"TLD\",\n",
    "        \"MEDIANFLOW\",\n",
    "        \"MOSSE\",\n",
    "        \"CSRT\",\n",
    "    ]\n",
    "    if tracker_type == 'BOOSTING':\n",
    "        tracker = cv2.legacy.TrackerBoosting_create()\n",
    "    if tracker_type == 'MIL':\n",
    "        tracker = cv2.TrackerMIL_create()\n",
    "    if tracker_type == 'KCF':\n",
    "        tracker = cv2.TrackerKCF_create()\n",
    "    if tracker_type == 'TLD':\n",
    "        tracker = cv2.legacy.TrackerTLD_create()\n",
    "    if tracker_type == 'MEDIANFLOW':\n",
    "        tracker = cv2.legacy.TrackerMedianFlow_create()\n",
    "    if tracker_type == 'MOSSE':\n",
    "        tracker = cv2.legacy.TrackerMOSSE_create()\n",
    "    if tracker_type == \"CSRT\":\n",
    "        tracker = cv2.TrackerCSRT_create()\n",
    "    return tracker\n",
    "\n",
    "def draw_bbox(frame, bbox, color=(255, 255, 255)):\n",
    "    p1 = (int(bbox[0]), int(bbox[1]))\n",
    "    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "    cv2.rectangle(frame, p1, p2, color, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef6d28",
   "metadata": {},
   "source": [
    "# Object Identification & Tracking Pipeline (ORB + MOG2)\n",
    "\n",
    " - Builds a feature dataset (keypoints/descriptors) for board game objects\n",
    "   from images in `media/photos/*`.\n",
    " - Uses background subtraction (MOG2) to find candidate regions in frames.\n",
    " - Computes ORB descriptors for candidates, matches to dataset, and if a\n",
    "   confident match is found, initializes a CSRT tracker for that object.\n",
    " - Tracks all initialized objects across the video and writes an output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b128ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters & Setup\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Directory with object images for the dataset\n",
    "DATASET_DIR = os.path.join('.', 'media', 'photos')  # adjust if needed\n",
    "\n",
    "# Path to the game video to process\n",
    "VIDEO_PATH = os.path.join('.', 'media', 'game.mp4')  # replace with your video\n",
    "OUTPUT_PATH = os.path.join('.', 'media', 'game_track.avi')\n",
    "\n",
    "# Background subtractor (MOG2)\n",
    "backSub = cv2.createBackgroundSubtractorMOG2(history=200, varThreshold=50, detectShadows=True)\n",
    "\n",
    "# Morphology kernels\n",
    "KERNEL_OPEN = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "KERNEL_CLOSE = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "\n",
    "# Minimum area to consider a contour a candidate (tune as needed)\n",
    "MIN_AREA = 500\n",
    "\n",
    "# ORB feature extractor\n",
    "ORB = cv2.ORB_create(nfeatures=1000)\n",
    "\n",
    "# BFMatcher for ORB (Hamming distance)\n",
    "BF = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build feature dataset from images\n",
    "def load_gray(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        return None\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img, gray\n",
    "\n",
    "def build_object_dataset(dataset_dir):\n",
    "    dataset = {}  # name -> { 'image': img, 'gray': gray, 'kps': kps, 'des': des }\n",
    "    image_paths = sorted(glob.glob(os.path.join(dataset_dir, '*.*')))\n",
    "    for p in image_paths:\n",
    "        name = os.path.splitext(os.path.basename(p))[0]\n",
    "        loaded = load_gray(p)\n",
    "        if loaded is None:\n",
    "            print(f'Warning: failed to load {p}')\n",
    "            continue\n",
    "        img, gray = loaded\n",
    "        kps, des = ORB.detectAndCompute(gray, None)\n",
    "        if des is None or len(kps) == 0:\n",
    "            print(f'Warning: no features for {name} ({p})')\n",
    "            continue\n",
    "        dataset[name] = {'image': img, 'gray': gray, 'kps': kps, 'des': des}\n",
    "    print(f'Dataset built: {len(dataset)} objects from {dataset_dir}')\n",
    "    return dataset\n",
    "\n",
    "# Ratio test filtering\n",
    "def good_matches_knn(des1, des2, ratio=0.75):\n",
    "    if des1 is None or des2 is None:\n",
    "        return []\n",
    "    matches = BF.knnMatch(des1, des2, k=2)\n",
    "    good = []\n",
    "    for m_n in matches:\n",
    "        if len(m_n) != 2:\n",
    "            continue\n",
    "        m, n = m_n\n",
    "        if m.distance < ratio * n.distance:\n",
    "            good.append(m)\n",
    "    return good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c79c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background removal and candidate extraction\n",
    "def extract_candidates(frame_bgr):\n",
    "    # Apply background subtraction\n",
    "    fgmask = backSub.apply(frame_bgr)\n",
    "    # Clean mask\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, KERNEL_OPEN)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, KERNEL_CLOSE)\n",
    "    # Threshold to binary\n",
    "    _, fgmask = cv2.threshold(fgmask, 200, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    candidates = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w * h < MIN_AREA:\n",
    "            continue\n",
    "        candidates.append((x, y, w, h))\n",
    "    return candidates, fgmask\n",
    "\n",
    "def crop_gray(frame_bgr, bbox):\n",
    "    x, y, w, h = bbox\n",
    "    roi = frame_bgr[y:y+h, x:x+w]\n",
    "    if roi.size == 0:\n",
    "        return None, None\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    return roi, gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f1d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match candidates to dataset\n",
    "def identify_candidate(gray_roi, dataset, min_good_matches=12):\n",
    "    # Compute ORB descriptors for ROI\n",
    "    kps_roi, des_roi = ORB.detectAndCompute(gray_roi, None)\n",
    "    if des_roi is None or len(kps_roi) == 0:\n",
    "        return None, 0\n",
    "    best_name = None\n",
    "    best_score = 0\n",
    "    for name, item in dataset.items():\n",
    "        good = good_matches_knn(des_roi, item['des'])\n",
    "        score = len(good)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_name = name\n",
    "    if best_name is None or best_score < min_good_matches:\n",
    "        return None, best_score\n",
    "    return best_name, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c45ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main pipeline: build dataset, detect introductions, and track\n",
    "def run_tracking(video_path=VIDEO_PATH, output_path=OUTPUT_PATH, dataset_dir=DATASET_DIR, min_match=12):\n",
    "    # Build dataset\n",
    "    dataset = build_object_dataset(dataset_dir)\n",
    "    if len(dataset) == 0:\n",
    "        print('No objects in dataset; aborting.')\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f'Cannot open video: {video_path}')\n",
    "        return\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS) or 25)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Active trackers per object name\n",
    "    trackers = {}  # name -> tracker\n",
    "    bboxes = {}    # name -> last bbox\n",
    "\n",
    "    frame_idx = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_idx += 1\n",
    "\n",
    "        # Update existing trackers\n",
    "        to_remove = []\n",
    "        for name, tracker in trackers.items():\n",
    "            ok, bbox = tracker.update(frame)\n",
    "            if ok:\n",
    "                bboxes[name] = bbox\n",
    "                draw_bbox(frame, bbox, (0, 255, 0))\n",
    "                # Overlay the object name near the bbox\n",
    "                x, y = int(bbox[0]), int(bbox[1])\n",
    "                label_y = max(y - 10, 15)\n",
    "                cv2.putText(frame, f\"{name}\", (x, label_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 3, cv2.LINE_AA)\n",
    "                cv2.putText(frame, f\"{name}\", (x, label_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            else:\n",
    "                # mark lost tracker; we'll try to re-detect\n",
    "                to_remove.append(name)\n",
    "        for name in to_remove:\n",
    "            del trackers[name]\n",
    "            del bboxes[name]\n",
    "\n",
    "        # If some objects are not tracked, try detecting new introductions\n",
    "        candidates, _ = extract_candidates(frame)\n",
    "        for bbox in candidates:\n",
    "            roi, gray_roi = crop_gray(frame, bbox)\n",
    "            if gray_roi is None:\n",
    "                continue\n",
    "            obj_name, score = identify_candidate(gray_roi, dataset, min_good_matches=min_match)\n",
    "            if obj_name is None:\n",
    "                continue\n",
    "            # If this object is not already tracked, initialize a tracker\n",
    "            if obj_name not in trackers:\n",
    "                trk = create_tracker('CSRT')\n",
    "                ok = trk.init(frame, bbox)\n",
    "                if ok:\n",
    "                    trackers[obj_name] = trk\n",
    "                    bboxes[obj_name] = bbox\n",
    "                    print(f\"[{frame_idx}] '{obj_name}' detected (matches={score}) and tracker initialized at {bbox}\")\n",
    "                    draw_bbox(frame, bbox, (255, 0, 0))\n",
    "                    # Overlay the object name on initialization\n",
    "                    x, y = int(bbox[0]), int(bbox[1])\n",
    "                    label_y = max(y - 10, 15)\n",
    "                    cv2.putText(frame, f\"{obj_name}\", (x, label_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 3, cv2.LINE_AA)\n",
    "                    cv2.putText(frame, f\"{obj_name}\", (x, label_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                else:\n",
    "                    print(f\"[{frame_idx}] Failed to init tracker for '{obj_name}'\")\n",
    "\n",
    "        writer.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    print('Tracking finished. Output saved to:', output_path)\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "# run_tracking()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f77eca",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "- Place one image per object in `media/photos`. The file name will be used as the object name (e.g., `pawn.png` → `pawn`).\n",
    "- Set `VIDEO_PATH` in Cell 4 to your game video file.\n",
    "- Optional: adjust `MIN_AREA` (Cell 4) and `min_match` argument in `run_tracking()` (Cell 8) for your scene.\n",
    "- Run Cells 4→8 in order. Uncomment the last line in Cell 8 (`run_tracking()`) to execute the pipeline.\n",
    "- The output video is written to `media/game_track.avi`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
